{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596374974093",
   "display_name": "Python 3.8.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"toxicity.xlsx\")\n",
    "df = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['Offensive', 'Very offensive', 'Neutral', 'Profanity',\n       'Extremely offensive', 'Unknown', 'Hate speech'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "814"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "neutral_df = df[df[\"label\"] == \"Neutral\"]\n",
    "neutral_size = neutral_df.shape[0]\n",
    "neutral_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_df = df[df[\"label\"].isin(['Offensive', 'Very offensive', 'Profanity', 'Extremely offensive', 'Hate speech'])].sample(neutral_size)\n",
    "toxic_df[\"label\"] = \"Toxic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      flirtation  identity_attack    insult  severe_toxicity  \\\n3       0.503426         0.407557  0.796685         0.854638   \n15      0.447052         0.242548  0.605072         0.718969   \n18      0.234309         0.327410  0.411611         0.755813   \n21      0.480975         0.495559  0.758837         0.747318   \n42      0.385286         0.268339  0.656422         0.747318   \n...          ...              ...       ...              ...   \n6741    0.588390         0.277701  0.924737         0.753536   \n9242    0.655491         0.609066  0.877252         0.886901   \n1139    0.510649         0.138321  0.702443         0.866124   \n428     0.570768         0.528850  0.909464         0.888702   \n3320    0.619894         0.254079  0.738578         0.747318   \n\n      sexually_explicit    threat    label  \n3              0.955973  0.343336  Neutral  \n15             0.381421  0.926245  Neutral  \n18             0.067329  0.980107  Neutral  \n21             0.652246  0.415748  Neutral  \n42             0.200259  0.926273  Neutral  \n...                 ...       ...      ...  \n6741           0.391835  0.344125    Toxic  \n9242           0.902304  0.471083    Toxic  \n1139           0.799199  0.292326    Toxic  \n428            0.838369  0.319839    Toxic  \n3320           0.965092  0.237207    Toxic  \n\n[1628 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>flirtation</th>\n      <th>identity_attack</th>\n      <th>insult</th>\n      <th>severe_toxicity</th>\n      <th>sexually_explicit</th>\n      <th>threat</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>0.503426</td>\n      <td>0.407557</td>\n      <td>0.796685</td>\n      <td>0.854638</td>\n      <td>0.955973</td>\n      <td>0.343336</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.447052</td>\n      <td>0.242548</td>\n      <td>0.605072</td>\n      <td>0.718969</td>\n      <td>0.381421</td>\n      <td>0.926245</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.234309</td>\n      <td>0.327410</td>\n      <td>0.411611</td>\n      <td>0.755813</td>\n      <td>0.067329</td>\n      <td>0.980107</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.480975</td>\n      <td>0.495559</td>\n      <td>0.758837</td>\n      <td>0.747318</td>\n      <td>0.652246</td>\n      <td>0.415748</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.385286</td>\n      <td>0.268339</td>\n      <td>0.656422</td>\n      <td>0.747318</td>\n      <td>0.200259</td>\n      <td>0.926273</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6741</th>\n      <td>0.588390</td>\n      <td>0.277701</td>\n      <td>0.924737</td>\n      <td>0.753536</td>\n      <td>0.391835</td>\n      <td>0.344125</td>\n      <td>Toxic</td>\n    </tr>\n    <tr>\n      <th>9242</th>\n      <td>0.655491</td>\n      <td>0.609066</td>\n      <td>0.877252</td>\n      <td>0.886901</td>\n      <td>0.902304</td>\n      <td>0.471083</td>\n      <td>Toxic</td>\n    </tr>\n    <tr>\n      <th>1139</th>\n      <td>0.510649</td>\n      <td>0.138321</td>\n      <td>0.702443</td>\n      <td>0.866124</td>\n      <td>0.799199</td>\n      <td>0.292326</td>\n      <td>Toxic</td>\n    </tr>\n    <tr>\n      <th>428</th>\n      <td>0.570768</td>\n      <td>0.528850</td>\n      <td>0.909464</td>\n      <td>0.888702</td>\n      <td>0.838369</td>\n      <td>0.319839</td>\n      <td>Toxic</td>\n    </tr>\n    <tr>\n      <th>3320</th>\n      <td>0.619894</td>\n      <td>0.254079</td>\n      <td>0.738578</td>\n      <td>0.747318</td>\n      <td>0.965092</td>\n      <td>0.237207</td>\n      <td>Toxic</td>\n    </tr>\n  </tbody>\n</table>\n<p>1628 rows Ã— 7 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "two_class_df = pd.concat([neutral_df, toxic_df])\n",
    "two_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = two_class_df.iloc[:, :-1]\n",
    "y = two_class_df.iloc[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'kernel': 'rbf', 'C': 10}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "clf = RandomizedSearchCV(svm, {\n",
    "     'C': [1, 10], \n",
    "     'kernel': ( 'rbf', 'poly')\n",
    "     },\n",
    "     n_jobs=-1)\n",
    "search = clf.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy of SVM classifier on training set: 0.89\nAccuracy of SVM classifier on test set: 0.83\nPrecision of SVM classifier: 0.88\nRecall of SVM classifier: 0.88\n"
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf', C=10)\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))\n",
    "y_pred = svm.predict(X)\n",
    "print('Precision of SVM classifier: {:.2f}'\n",
    "     .format(precision_score(y, y_pred, average='macro')))\n",
    "print('Recall of SVM classifier: {:.2f}'\n",
    "     .format(recall_score(y, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'solver': 'lbfgs',\n 'learning_rate': 'constant',\n 'alpha': 0.0001,\n 'activation': 'relu'}"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NN = MLPClassifier()\n",
    "clf = RandomizedSearchCV(NN, {\n",
    "    'activation': ['tanh', 'relu', 'logistic'],\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    'alpha': [0.0001, 0.9],\n",
    "    'learning_rate': ['constant','adaptive']\n",
    "    },\n",
    "    n_jobs=-1)\n",
    "search = clf.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy of NN classifier on training set: 0.88\nAccuracy of NN classifier on test set: 0.83\nPrecision of SVM classifier: 0.87\nRecall of SVM classifier: 0.87\n"
    }
   ],
   "source": [
    "NN = MLPClassifier(activation='relu',solver='lbfgs', alpha=0.0001, learning_rate='constant')\n",
    "NN.fit(X_train, y_train)\n",
    "print('Accuracy of NN classifier on training set: {:.2f}'\n",
    "     .format(NN.score(X_train, y_train)))\n",
    "print('Accuracy of NN classifier on test set: {:.2f}'\n",
    "     .format(NN.score(X_test, y_test)))\n",
    "y_pred = NN.predict(X)\n",
    "print('Precision of NN classifier: {:.2f}'\n",
    "     .format(precision_score(y, y_pred, average='macro')))\n",
    "print('Recall of NN classifier: {:.2f}'\n",
    "     .format(recall_score(y, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'n_estimators': 700, 'max_features': 'auto'}"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier()\n",
    "clf = RandomizedSearchCV(RF, { \n",
    "    'n_estimators': [200, 700],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "    },\n",
    "    n_jobs=-1)\n",
    "search = clf.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy of RF classifier on training set: 1.00\nAccuracy of RF classifier on test set: 0.83\nPrecision of SVM classifier: 0.96\nRecall of SVM classifier: 0.96\n"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=700, max_features='auto')\n",
    "RF.fit(X_train, y_train)\n",
    "print('Accuracy of RF classifier on training set: {:.2f}'\n",
    "     .format(RF.score(X_train, y_train)))\n",
    "print('Accuracy of RF classifier on test set: {:.2f}'\n",
    "     .format(RF.score(X_test, y_test)))\n",
    "y_pred = RF.predict(X)\n",
    "print('Precision of RF classifier: {:.2f}'\n",
    "     .format(precision_score(y, y_pred, average='macro')))\n",
    "print('Recall of RF classifier: {:.2f}'\n",
    "     .format(recall_score(y, y_pred, average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the different models is about the same on the test set, but the precision, `tp / (tp + fp)`, and recall, `tp / (tp + fn)`, of the Random Forest classifier are much better than the other 2 models, which is important given the context of this model (possibly punishing players due to their toxic behaviour), so my selection is going to be a Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(n_estimators=700, max_features='log2')\n",
    "RF.fit(X, y)"
   ]
  }
 ]
}